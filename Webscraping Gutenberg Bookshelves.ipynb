{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Gutenberg: scraping, downloading, and metadata\n",
    "This notebook provides a single workflow with options for scraping a bookshelf, downloading texts, cleaning, and writing metadata CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BEGIN_TEXT = {\n",
    "    \"*END*THE SMALL PRINT\",\n",
    "    \"*** START OF THE PROJECT GUTENBERG\",\n",
    "    \"*** START OF THIS PROJECT GUTENBERG\",\n",
    "    \" *** START OF THIS PROJECT GUTENBERG\",\n",
    "    \"***START OF THE PROJECT GUTENBERG\",\n",
    "    \"*** START OF THE COPYRIGHTED\",\n",
    "    \"**The Project Gutenberg\",\n",
    "    \"*SMALL PRINT!\",\n",
    "    \"****     SMALL PRINT!\",\n",
    "    \"[\\\"Small Print\\\" V.\",\n",
    "    \"This etext was prepared by\",\n",
    "    \"This etext was produced by\",\n",
    "    \"This Etext was prepared by\",\n",
    "    \"This eBook was prepared by\",\n",
    "    \"This Project Gutenberg Etext was prepared by\",\n",
    "    \"E-text prepared by\",\n",
    "    \"Produced by\",\n",
    "    \"Distributed Proofreading Team\",\n",
    "    \"Proofreading Team at http://www.pgdp.net\",\n",
    "    \"http://gallica.bnf.fr)\",\n",
    "    \"      http://archive.org/details/\",\n",
    "    \"      (http://www.ibiblio.org/gutenberg/\",\n",
    "    \"http://www.pgdp.net\",\n",
    "    \"by The Internet Archive)\",\n",
    "    \"by The Internet Archive/Canadian Libraries\",\n",
    "    \"by The Internet Archive/American Libraries\",\n",
    "    \"public domain material from the Internet Archive\",\n",
    "    \"Internet Archive)\",\n",
    "    \"Internet Archive/Canadian Libraries\",\n",
    "    \"Internet Archive/American Libraries\",\n",
    "    \"material from the Google Print project\",\n",
    "    \"*END THE SMALL PRINT\",\n",
    "    \"The Project Gutenberg\",\n",
    "    \"http://gutenberg.spiegel.de/ erreichbar.\",\n",
    "    \"http://gutenberg2000.de erreichbar.\",\n",
    "    \"Project Runeberg publishes\",\n",
    "    \"Beginning of this Project Gutenberg\",\n",
    "    \"Project Gutenberg Online Distributed\",\n",
    "    \"Gutenberg Online Distributed\",\n",
    "    \"the Project Gutenberg Online Distributed\",\n",
    "    \"the Project Gutenberg Online Distributed Proofreading Team\",\n",
    "    \"Project Gutenberg TEI\",\n",
    "    \"Gutenberg Distributed Proofreaders\",\n",
    "    \"Project Gutenberg Distributed Proofreaders\",\n",
    "    \"and the Project Gutenberg Online Distributed Proofreading Team\",\n",
    "    \"Mary Meehan, and the Project Gutenberg Online Distributed Proofreading\",\n",
    "    \"                this Project Gutenberg edition.\",\n",
    "    \"More information about this book is at the top of this file.\",\n",
    "    \"tells you about restrictions in how the file may be used.\",\n",
    "    \"of the etext through OCR.\",\n",
    "    \"*****These eBooks Were Prepared By Thousands of Volunteers!*****\",\n",
    "    \"We need your donations more than ever!\",\n",
    "}\n",
    "\n",
    "END_TEXT = {\n",
    "    \"*** END OF THE PROJECT GUTENBERG\",\n",
    "    \"*** END OF THIS PROJECT GUTENBERG\",\n",
    "    \" *** END OF THIS PROJECT GUTENBERG\",\n",
    "    \"        ***END OF THE PROJECT GUTENBERG\",\n",
    "    \"***END OF THE PROJECT GUTENBERG\",\n",
    "    \"*** END OF THE COPYRIGHTED\",\n",
    "    \"End of the Project Gutenberg\",\n",
    "    \" End of the Project Gutenberg\",\n",
    "    \"End of The Project Gutenberg\",\n",
    "    \"End of Project Gutenberg\",\n",
    "    \"End of this Project Gutenberg\",\n",
    "    \"END OF PROJECT GUTENBERG\",\n",
    "    \"End of this is COPYRIGHTED\",\n",
    "    \"by Project Gutenberg\",\n",
    "    \"The Project Gutenberg Etext of \",\n",
    "    \"**This is a COPYRIGHTED Project Gutenberg Etext, Details Above**\",\n",
    "    \"Ende dieses Project Gutenberg\",\n",
    "    \"Ende dieses Projekt Gutenberg\",\n",
    "    \"Ende dieses Etextes \",\n",
    "    \"Ende diese Project Gutenberg\",\n",
    "    \"Ende dieses Project Gutenber\",\n",
    "    \"Fin de Project Gutenberg\",\n",
    "    \"More information about this book is at the top of this file.\",\n",
    "    \"We need your donations more than ever!\",\n",
    "}\n",
    "\n",
    "def fetch_url(url):\n",
    "    request = urllib.request.Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        return response.read()\n",
    "\n",
    "def soup_from_url(url):\n",
    "    return BeautifulSoup(fetch_url(url), \"html.parser\")\n",
    "\n",
    "def extract_book_ids(bookshelf_url):\n",
    "    soup = soup_from_url(bookshelf_url)\n",
    "    ids = []\n",
    "    seen = set()\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"]\n",
    "        match = re.search(r\"/ebooks/(\\d+)\", href)\n",
    "        if not match:\n",
    "            continue\n",
    "        book_id = match.group(1)\n",
    "        if book_id in seen:\n",
    "            continue\n",
    "        seen.add(book_id)\n",
    "        ids.append(book_id)\n",
    "    return ids\n",
    "\n",
    "def safe_slug(text):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"-\", text).strip(\"-\")\n",
    "    return slug[:80] if slug else \"untitled\"\n",
    "\n",
    "def parse_bibrec(soup):\n",
    "    data = {\"title\": \"\", \"author\": \"\", \"language\": \"\", \"subject\": []}\n",
    "    bibrec = soup.find(\"table\", id=\"bibrec\")\n",
    "    if not bibrec:\n",
    "        return data\n",
    "    for row in bibrec.find_all(\"tr\"):\n",
    "        header = row.find(\"th\")\n",
    "        value = row.find(\"td\")\n",
    "        if not header or not value:\n",
    "            continue\n",
    "        key = header.get_text(strip=True).lower()\n",
    "        if key == \"title\":\n",
    "            data[\"title\"] = value.get_text(\" \", strip=True)\n",
    "        elif key == \"author\":\n",
    "            data[\"author\"] = value.get_text(\" \", strip=True)\n",
    "        elif key == \"language\":\n",
    "            data[\"language\"] = value.get_text(\" \", strip=True)\n",
    "        elif key == \"subject\":\n",
    "            data[\"subject\"].append(value.get_text(\" \", strip=True))\n",
    "    return data\n",
    "\n",
    "def download_text(book_id):\n",
    "    urls = [\n",
    "        f\"https://www.gutenberg.org/ebooks/{book_id}.txt.utf-8\",\n",
    "        f\"https://www.gutenberg.org/cache/epub/{book_id}/pg{book_id}.txt\",\n",
    "        f\"https://www.gutenberg.org/cache/epub/{book_id}/pg{book_id}.txt.utf-8\",\n",
    "    ]\n",
    "    for url in urls:\n",
    "        try:\n",
    "            data = fetch_url(url)\n",
    "            text = data.decode(\"utf-8\", errors=\"replace\")\n",
    "            if text.strip():\n",
    "                return text, url\n",
    "        except urllib.error.HTTPError:\n",
    "            continue\n",
    "        except urllib.error.URLError:\n",
    "            continue\n",
    "    return \"\", \"\"\n",
    "\n",
    "def strip_gutenberg(text):\n",
    "    lines = text.splitlines()\n",
    "    start = 0\n",
    "    end = len(lines)\n",
    "    for i, line in enumerate(lines):\n",
    "        check = line.strip()\n",
    "        if any(check.startswith(marker) for marker in BEGIN_TEXT):\n",
    "            start = i + 1\n",
    "            break\n",
    "    for i, line in enumerate(lines):\n",
    "        check = line.strip()\n",
    "        if any(check.startswith(marker) for marker in END_TEXT):\n",
    "            end = i\n",
    "            break\n",
    "    return \"\\n\".join(lines[start:end]).strip()\n",
    "\n",
    "def write_text(path, text):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "def run_bookshelf_pipeline(bookshelf_url, max_books, out_dir, sleep_sec=0.2, download_raw=True, write_clean=True, write_metadata=True):\n",
    "    out_dir = Path(out_dir).resolve()\n",
    "    raw_dir = out_dir / \"raw\"\n",
    "    clean_dir = out_dir / \"clean\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    book_ids = extract_book_ids(bookshelf_url)[:max_books]\n",
    "    metadata_rows = []\n",
    "\n",
    "    for book_id in book_ids:\n",
    "        book_url = f\"https://www.gutenberg.org/ebooks/{book_id}\"\n",
    "        try:\n",
    "            soup = soup_from_url(book_url)\n",
    "        except urllib.error.HTTPError:\n",
    "            continue\n",
    "        except urllib.error.URLError:\n",
    "            continue\n",
    "\n",
    "        meta = parse_bibrec(soup)\n",
    "        title = meta[\"title\"] or f\"gutenberg-{book_id}\"\n",
    "        slug = safe_slug(title)\n",
    "        raw_path = raw_dir / f\"{book_id}__{slug}.txt\"\n",
    "        clean_path = clean_dir / f\"{book_id}__{slug}.txt\"\n",
    "        text = \"\"\n",
    "        if download_raw or write_clean:\n",
    "            text, _ = download_text(book_id)\n",
    "            if not text:\n",
    "                continue\n",
    "            if download_raw:\n",
    "                write_text(raw_path, text)\n",
    "            if write_clean:\n",
    "                write_text(clean_path, strip_gutenberg(text))\n",
    "\n",
    "        if write_metadata:\n",
    "            metadata_rows.append(\n",
    "                {\n",
    "                    \"title\": title,\n",
    "                    \"author\": meta[\"author\"],\n",
    "                    \"gutenberg_id\": book_id,\n",
    "                    \"language\": meta[\"language\"],\n",
    "                    \"subject\": \"; \".join(meta[\"subject\"]) if meta[\"subject\"] else \"\",\n",
    "                    \"url\": book_url,\n",
    "                    \"local_path\": str((clean_path if write_clean else raw_path).relative_to(out_dir.parent.parent)) if (download_raw or write_clean) else \"\",\n",
    "                }\n",
    "            )\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    if write_metadata:\n",
    "        csv_path = out_dir / \"metadata.csv\"\n",
    "        with csv_path.open(\"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "            fieldnames = [\n",
    "                \"title\",\n",
    "                \"author\",\n",
    "                \"gutenberg_id\",\n",
    "                \"language\",\n",
    "                \"subject\",\n",
    "                \"url\",\n",
    "                \"local_path\",\n",
    "            ]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(metadata_rows)\n",
    "        print(f\"Wrote {len(metadata_rows)} items to {csv_path}\")\n",
    "\n",
    "    return metadata_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set the bookshelf URL, output folder, and toggles below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookshelf_url = \"https://www.gutenberg.org/ebooks/bookshelf/68\"\n",
    "max_books = 2\n",
    "out_dir = Path(\"outputs\")\n",
    "sleep_sec = 0.2\n",
    "\n",
    "download_raw = True\n",
    "write_clean = True\n",
    "write_metadata = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline\n",
    "This produces optional raw/clean text files and a metadata CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 2 items to /Users/alexwermer-colan/Code/SF-Nexus/webscraping-SF/gutenberg/outputs/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "metadata_rows = run_bookshelf_pipeline(\n",
    "    bookshelf_url=bookshelf_url,\n",
    "    max_books=max_books,\n",
    "    out_dir=out_dir,\n",
    "    sleep_sec=sleep_sec,\n",
    "    download_raw=download_raw,\n",
    "    write_clean=write_clean,\n",
    "    write_metadata=write_metadata,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download-only example (bookshelf by women)\n",
    "Raw .txt only, no metadata or cleaning. Update the URL if the wiki page changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_only_url = \"https://www.gutenberg.org/ebooks/bookshelf/68\"\n",
    "download_only_dir = Path(\"downloads\")\n",
    "\n",
    "_ = run_bookshelf_pipeline(\n",
    "    bookshelf_url=download_only_url,\n",
    "    max_books=10,\n",
    "    out_dir=download_only_dir,\n",
    "    sleep_sec=sleep_sec,\n",
    "    download_raw=True,\n",
    "    write_clean=False,\n",
    "    write_metadata=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: package-based Gutenberg API\n",
    "Gutenberg PyPl: https://github.com/ageitgey/Gutenberg\n",
    "Gutenberg HTTP: https://github.com/c-w/gutenberg-http/\n",
    "\n",
    "If a mirror error occurs, set a mirror such as https://gutenberg.pglaf.org/ in your API calls.\n",
    "If bookshelf wiki pages 404, prefer the numeric bookshelf endpoints like https://www.gutenberg.org/ebooks/bookshelf/68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the gutenberg package to use API queries.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from gutenberg.acquire import load_etext\n",
    "    from gutenberg.cleanup import strip_headers\n",
    "\n",
    "    text = strip_headers(load_etext(2701, mirror=\"https://gutenberg.pglaf.org/\")).strip()\n",
    "    print(text[:500])\n",
    "except ImportError:\n",
    "    print(\"Install the gutenberg package to use API queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata cache (required for `gutenberg.query`)\n",
    "Populate the cache once, then queries are fast. This can take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the gutenberg package to configure metadata cache.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from gutenberg.acquire import set_metadata_cache\n",
    "    from gutenberg.acquire.metadata import SqliteMetadataCache\n",
    "\n",
    "    sqlite_cache = SqliteMetadataCache(\"/tmp/gutenberg_cache.sqlite\")\n",
    "    sqlite_cache.populate()\n",
    "    set_metadata_cache(sqlite_cache)\n",
    "except ImportError:\n",
    "    print(\"Install the gutenberg package to configure metadata cache.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the gutenberg package to populate the cache.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from gutenberg.acquire import get_metadata_cache\n",
    "    cache = get_metadata_cache()\n",
    "    cache.populate()\n",
    "except ImportError:\n",
    "    print(\"Install the gutenberg package to populate the cache.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional metadata queries (requires populated cache)\n",
    "# from gutenberg.query import get_etexts, get_metadata\n",
    "# print(get_metadata(\"title\", 2701))\n",
    "# print(get_metadata(\"author\", 2701))\n",
    "# print(get_etexts(\"title\", \"Moby Dick; Or, The Whale\"))\n",
    "# print(get_etexts(\"author\", \"Melville, Hermann\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
